{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2462d890-c1ac-4555-82c2-a91e0123d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb1684-7788-491c-9895-32ca2caccbe6",
   "metadata": {},
   "source": [
    "The original data was split into train and test folders, but in this case the images were unified keeping their structure for the labels.\n",
    "This way get 4 folders: glioma_tumor, meninglioma_tumor, no_tumor and pituitary_tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3af3fec-e383-4385-884b-7c80ea46b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in each class:\n",
      "glioma_tumor: 926\n",
      "meningioma_tumor: 937\n",
      "no_tumor: 500\n",
      "pituitary_tumor: 901\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = 'data/Unified'\n",
    "\n",
    "# List the subfolders in the training data folder\n",
    "subfolders = os.listdir(data_path)\n",
    "\n",
    "# Initialize a dictionary to hold the count of images in each subfolder\n",
    "image_counts_data = {}\n",
    "\n",
    "# Count the number of images in each subfolder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(data_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        num_images = len(os.listdir(subfolder_path))\n",
    "        image_counts_data[subfolder] = num_images\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of images in each class:\")\n",
    "for subfolder, count in image_counts_data.items():\n",
    "    print(f\"{subfolder}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267cc5e-8f12-4e65-9e1f-7249da6b5821",
   "metadata": {},
   "source": [
    "As we can see the no_tumor class is underrepresented compated to the tumor clases. So we will use the ImageDataGenerator class to generate images from the no_tumor class so it reaches a number equal to the highest represented class (in this case meningioma_tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b4ee5d-66c9-4bac-8b97-a859315facb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images already exist. Skipping augmentation.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "original_training_data_path = 'data/Unified'\n",
    "augmented_training_data_path = 'data/Augmented'\n",
    "\n",
    "# Initialize ImageDataGenerator with augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment images of a specific class\n",
    "def augment_images(class_name, target_count):\n",
    "    class_path = os.path.join(original_training_data_path, class_name)\n",
    "    augmented_class_path = os.path.join(augmented_training_data_path, class_name)\n",
    "    \n",
    "    # Create subfolder in augmented_training if it doesn't exist\n",
    "    if not os.path.exists(augmented_class_path):\n",
    "        os.makedirs(augmented_class_path)\n",
    "    \n",
    "    # List existing images\n",
    "    existing_images = os.listdir(class_path)\n",
    "    existing_count = len(existing_images)\n",
    "    \n",
    "    # Copy existing images to augmented_training\n",
    "    for image_name in existing_images:\n",
    "        src_path = os.path.join(class_path, image_name)\n",
    "        dst_path = os.path.join(augmented_class_path, image_name)\n",
    "        if not os.path.exists(dst_path):  # Check if image already exists in destination\n",
    "            shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    # Start augmentation until target_count is reached\n",
    "    for i in range(target_count - existing_count):\n",
    "        # Randomly select an image to augment\n",
    "        image_name = np.random.choice(existing_images)\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "        img = image.load_img(image_path, target_size=(128, 128))\n",
    "        \n",
    "        # Convert to numpy array and add batch dimension\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        # Generate augmented image\n",
    "        augmented_images = next(datagen.flow(x, batch_size=1))\n",
    "        augmented_image = image.array_to_img(augmented_images[0])\n",
    "        \n",
    "        # Save augmented image\n",
    "        save_path = os.path.join(augmented_class_path, f\"aug_{i}_{image_name}\")\n",
    "        augmented_image.save(save_path)\n",
    "\n",
    "# Function to copy images of a specific class\n",
    "def copy_images(class_name):\n",
    "    class_path = os.path.join(original_training_data_path, class_name)\n",
    "    augmented_class_path = os.path.join(augmented_training_data_path, class_name)\n",
    "    \n",
    "    # Create subfolder in augmented_training if it doesn't exist\n",
    "    if not os.path.exists(augmented_class_path):\n",
    "        os.makedirs(augmented_class_path)\n",
    "    \n",
    "    # List existing images\n",
    "    existing_images = os.listdir(class_path)\n",
    "    \n",
    "    # Copy existing images to augmented_training\n",
    "    for image_name in existing_images:\n",
    "        src_path = os.path.join(class_path, image_name)\n",
    "        dst_path = os.path.join(augmented_class_path, image_name)\n",
    "        if not os.path.exists(dst_path):  # Check if image already exists in destination\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Get the number of images in each class in the original training data\n",
    "image_counts = {class_name: len(os.listdir(os.path.join(original_training_data_path, class_name))) \n",
    "                for class_name in os.listdir(original_training_data_path) \n",
    "                if os.path.isdir(os.path.join(original_training_data_path, class_name))}\n",
    "\n",
    "# Find the class with the maximum number of images\n",
    "max_count = max(image_counts.values())\n",
    "\n",
    "# Check if augmentation for 'no_tumor' is needed\n",
    "augmented_no_tumor_path = os.path.join(augmented_training_data_path, 'no_tumor')\n",
    "if not os.path.exists(augmented_no_tumor_path) or len(os.listdir(augmented_no_tumor_path)) < max_count:\n",
    "    # Create augmented_training folder if it doesn't exist\n",
    "    if not os.path.exists(augmented_training_data_path):\n",
    "        os.makedirs(augmented_training_data_path)\n",
    "    \n",
    "    augment_images('no_tumor', max_count)\n",
    "else:\n",
    "    print(\"Augmented images already exist. Skipping augmentation.\")\n",
    "\n",
    "# Copy all original training images to augmented_training\n",
    "for class_name in image_counts.keys():\n",
    "    if class_name != 'no_tumor':  # We've already handled no_tumor\n",
    "        copy_images(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89829636-fce8-477c-9d1d-965f16f800b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in each class after data augmentation:\n",
      "glioma_tumor: 926\n",
      "meningioma_tumor: 937\n",
      "no_tumor: 937\n",
      "pituitary_tumor: 901\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = 'data/Augmented'\n",
    "\n",
    "# List the subfolders in the training data folder\n",
    "subfolders = os.listdir(data_path)\n",
    "\n",
    "# Initialize a dictionary to hold the count of images in each subfolder\n",
    "image_counts_data = {}\n",
    "\n",
    "# Count the number of images in each subfolder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(data_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        num_images = len(os.listdir(subfolder_path))\n",
    "        image_counts_data[subfolder] = num_images\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of images in each class after data augmentation:\")\n",
    "for subfolder, count in image_counts_data.items():\n",
    "    print(f\"{subfolder}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39fdaa-8310-46e3-97bc-995feb1dbffc",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0dcbc0-572e-4431-8eca-1a44dcfdb021",
   "metadata": {},
   "source": [
    "Now that we have a better distribution of classes a train and test data set are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12930136-53f3-4007-b082-5de71e795e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_height, img_width = 128, 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078bf9ff-77ca-4888-b3d1-86bee64a0536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3701 files belonging to 4 classes.\n",
      "Using 2961 files for training.\n",
      "Using 740 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"both\",\n",
    "  seed=42,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d63cb27-05b0-47d8-8251-c7a1e0c5a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23982f9d-3339-4bc5-aaef-d32efd843299",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ac815-089f-4d5b-87f0-9d3c9da737eb",
   "metadata": {},
   "source": [
    "Now that we have the train and test datasets we will try some configurations for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9db9ba-b9c9-453e-8136-265086d75a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 13s 129ms/step - loss: 1.0158 - accuracy: 0.5819 - val_loss: 0.8790 - val_accuracy: 0.6365\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 12s 125ms/step - loss: 0.5906 - accuracy: 0.7670 - val_loss: 0.5465 - val_accuracy: 0.8095\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 12s 126ms/step - loss: 0.3936 - accuracy: 0.8551 - val_loss: 0.4813 - val_accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 12s 128ms/step - loss: 0.2583 - accuracy: 0.9027 - val_loss: 0.5143 - val_accuracy: 0.8432\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 12s 128ms/step - loss: 0.1666 - accuracy: 0.9392 - val_loss: 0.5474 - val_accuracy: 0.8284\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 12s 125ms/step - loss: 0.1019 - accuracy: 0.9642 - val_loss: 0.4322 - val_accuracy: 0.9108\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 12s 128ms/step - loss: 0.0637 - accuracy: 0.9814 - val_loss: 0.4353 - val_accuracy: 0.9068\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 12s 128ms/step - loss: 0.0277 - accuracy: 0.9949 - val_loss: 0.5527 - val_accuracy: 0.8878\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 12s 127ms/step - loss: 0.0467 - accuracy: 0.9882 - val_loss: 0.6207 - val_accuracy: 0.8811\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 12s 128ms/step - loss: 0.0668 - accuracy: 0.9794 - val_loss: 0.4710 - val_accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Build the model\n",
    "model_1 = keras.Sequential([\n",
    "      layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_1 = model_1.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc685d5-6ba9-4f51-a755-2a11234595d4",
   "metadata": {},
   "source": [
    "The accuracy on the train data is much higher than the validation accuracy, so we will try other configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60028313-9b88-4e61-9000-06ef4e97f3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 12s 118ms/step - loss: 1.1021 - accuracy: 0.5623 - val_loss: 0.8041 - val_accuracy: 0.6541\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 11s 120ms/step - loss: 0.5605 - accuracy: 0.7960 - val_loss: 0.6057 - val_accuracy: 0.7676\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 11s 112ms/step - loss: 0.3528 - accuracy: 0.8734 - val_loss: 0.4988 - val_accuracy: 0.8081\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 11s 116ms/step - loss: 0.2040 - accuracy: 0.9321 - val_loss: 0.4679 - val_accuracy: 0.8338\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 11s 118ms/step - loss: 0.1059 - accuracy: 0.9686 - val_loss: 0.4974 - val_accuracy: 0.8473\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 11s 118ms/step - loss: 0.0888 - accuracy: 0.9733 - val_loss: 0.5751 - val_accuracy: 0.8419\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 11s 116ms/step - loss: 0.0465 - accuracy: 0.9899 - val_loss: 0.4953 - val_accuracy: 0.8851\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 11s 113ms/step - loss: 0.0393 - accuracy: 0.9905 - val_loss: 0.5966 - val_accuracy: 0.8662\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 11s 116ms/step - loss: 0.0327 - accuracy: 0.9936 - val_loss: 0.6195 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 11s 117ms/step - loss: 0.0270 - accuracy: 0.9949 - val_loss: 0.6611 - val_accuracy: 0.8649\n"
     ]
    }
   ],
   "source": [
    "# Removing the Conv2D(64, 3, padding='same', activation='relu') and a MaxPooling2D() layers\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Build the model\n",
    "model_2 = keras.Sequential([\n",
    "      layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_2 = model_2.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48e5867-ad5d-4a86-9476-fce31da48ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 15s 146ms/step - loss: 1.1410 - accuracy: 0.5171 - val_loss: 1.0112 - val_accuracy: 0.6081\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 14s 152ms/step - loss: 0.9381 - accuracy: 0.6109 - val_loss: 0.7611 - val_accuracy: 0.7068\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 14s 149ms/step - loss: 0.8065 - accuracy: 0.6663 - val_loss: 0.7476 - val_accuracy: 0.6784\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 14s 148ms/step - loss: 0.7247 - accuracy: 0.6967 - val_loss: 0.6343 - val_accuracy: 0.7608\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 14s 146ms/step - loss: 0.6702 - accuracy: 0.7298 - val_loss: 0.6101 - val_accuracy: 0.7703\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 14s 147ms/step - loss: 0.5816 - accuracy: 0.7663 - val_loss: 0.5782 - val_accuracy: 0.7878\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 14s 147ms/step - loss: 0.5298 - accuracy: 0.7852 - val_loss: 0.7223 - val_accuracy: 0.7351\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 14s 145ms/step - loss: 0.5036 - accuracy: 0.7984 - val_loss: 0.5504 - val_accuracy: 0.8122\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 14s 148ms/step - loss: 0.4655 - accuracy: 0.8163 - val_loss: 0.4735 - val_accuracy: 0.8284\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 14s 149ms/step - loss: 0.4327 - accuracy: 0.8345 - val_loss: 0.4956 - val_accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_3 = keras.Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_3 = model_3.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4a5e7-135d-447d-9b6b-765ed5e6403e",
   "metadata": {},
   "source": [
    "In this an augmentation layer is added at the start and a dropout layer.\n",
    "For the purposes of this excercise ~83% of accuracy will be considered acceptable so the model is saved so it can be used in a predictive system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3b3245-6f8a-43dd-8872-67493398845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_3.save(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8e776-961d-4e81-8e0b-59f882cbb365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
